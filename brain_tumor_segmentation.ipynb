{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import Libraries","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import os\nimport glob\nimport random\nimport cv2\nfrom PIL import Image\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.data as data\nfrom torch.utils.data import DataLoader\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nfrom torchvision.utils import make_grid\nimport torchvision.transforms as tt\nimport albumentations as A\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:11:52.794352Z","iopub.execute_input":"2021-12-28T12:11:52.794670Z","iopub.status.idle":"2021-12-28T12:11:56.710275Z","shell.execute_reply.started":"2021-12-28T12:11:52.794582Z","shell.execute_reply":"2021-12-28T12:11:56.709474Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"### Set device\nSet device to use CUDA if available","metadata":{}},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Using {} device\".format(device))","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:11:56.715370Z","iopub.execute_input":"2021-12-28T12:11:56.715857Z","iopub.status.idle":"2021-12-28T12:11:56.774230Z","shell.execute_reply.started":"2021-12-28T12:11:56.715817Z","shell.execute_reply":"2021-12-28T12:11:56.773512Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### Set Seed\n\nSet seed for reproducibilty","metadata":{}},{"cell_type":"code","source":"def set_seed(seed = 0):\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    \nset_seed()","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:11:56.778783Z","iopub.execute_input":"2021-12-28T12:11:56.779616Z","iopub.status.idle":"2021-12-28T12:11:56.791667Z","shell.execute_reply.started":"2021-12-28T12:11:56.779574Z","shell.execute_reply":"2021-12-28T12:11:56.790971Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Load files path in a dataframe\n\nWe first load the path of all the image files as well as their corresponding mask files in a dataframe. \n\nWe also create a function `diagnonsis` which will read through all the mask files and return those files which have numpy value > 0 (not blank black mask images).\nWe then add the list of non blank mask images as a diagnonsis column in the dataframe.","metadata":{}},{"cell_type":"code","source":"ROOT_PATH = '../input/lgg-mri-segmentation/kaggle_3m/'\n\nmask_files = glob.glob(ROOT_PATH + '*/*_mask*')\nimage_files = [file.replace('_mask', '') for file in mask_files]\n\ndef diagnosis(mask_path):\n    return 1 if np.max(cv2.imread(mask_path)) > 0 else 0\n\nfiles_df = pd.DataFrame({\"image_path\": image_files,\n                  \"mask_path\": mask_files,\n                  \"diagnosis\": [diagnosis(x) for x in mask_files]})\n\nfiles_df","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:11:56.796403Z","iopub.execute_input":"2021-12-28T12:11:56.797994Z","iopub.status.idle":"2021-12-28T12:12:21.707855Z","shell.execute_reply.started":"2021-12-28T12:11:56.797955Z","shell.execute_reply":"2021-12-28T12:12:21.707100Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Understand data distribution","metadata":{}},{"cell_type":"code","source":"ax = files_df['diagnosis'].value_counts().plot(kind='bar', stacked=True, figsize=(6,6), color=['green', 'red'])\nax.set_title('Data Distribution', fontsize=15)\nax.set_ylabel('No. of Images', fontsize=15)\nax.set_xticklabels(['No Tumor', 'Tumor'], fontsize=12, rotation=0)\nfor i, rows in enumerate(files_df['diagnosis'].value_counts().values):\n    ax.annotate(int(rows), xy=(i, rows+12), ha='center', fontweight='bold', fontsize=12)","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:12:21.710094Z","iopub.execute_input":"2021-12-28T12:12:21.710308Z","iopub.status.idle":"2021-12-28T12:12:21.950503Z","shell.execute_reply.started":"2021-12-28T12:12:21.710282Z","shell.execute_reply":"2021-12-28T12:12:21.949771Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"We have a total of 3929 samples, out of which 1373 are tumor positive, and 2556 are not.","metadata":{}},{"cell_type":"markdown","source":"## Train-Validation-Test split\n\nWe split the data into train, validation and test datasets using the `tran_test_split` function from **sklearn**. We use `stratify` parameter to evenly distribute the number of tumor positive samples among each set.","metadata":{}},{"cell_type":"code","source":"train_df, val_df = train_test_split(files_df, stratify=files_df['diagnosis'], test_size=0.1, random_state=0)\ntrain_df = train_df.reset_index(drop=True)\nval_df = val_df.reset_index(drop=True)\n\ntrain_df, test_df = train_test_split(train_df, stratify=train_df['diagnosis'], test_size=0.15, random_state=0)\ntrain_df = train_df.reset_index(drop=True)\ntest_df = test_df.reset_index(drop=True)\n\nprint(\"Train: {}\\nVal: {}\\nTest: {}\".format(train_df.shape, val_df.shape, test_df.shape))","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:12:21.951929Z","iopub.execute_input":"2021-12-28T12:12:21.952379Z","iopub.status.idle":"2021-12-28T12:12:21.975614Z","shell.execute_reply.started":"2021-12-28T12:12:21.952328Z","shell.execute_reply":"2021-12-28T12:12:21.974742Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Viewing the dataset","metadata":{}},{"cell_type":"code","source":"set_seed()\n\nimages, masks = [], []\ndf_positive = train_df[train_df['diagnosis']==1].sample(5).values\n\nfor sample in df_positive:\n    img = cv2.imread(sample[0])\n    mask = cv2.imread(sample[1])\n    images.append(img)\n    masks.append(mask)\nimages = np.hstack(np.array(images))\nmasks = np.hstack(np.array(masks))\n\nfig = plt.figure(figsize=(15,10))\ngrid = ImageGrid(fig, 111, nrows_ncols=(3,1), axes_pad=0.4)\n\ngrid[0].imshow(images)\ngrid[0].set_title('Images', fontsize=15)\ngrid[0].axis('off')\ngrid[1].imshow(masks)\ngrid[1].set_title('Masks', fontsize=15)\ngrid[1].axis('off')\ngrid[2].imshow(images)\ngrid[2].imshow(masks, alpha=0.4)\ngrid[2].set_title('Brain MRI with mask', fontsize=15)\ngrid[2].axis('off')","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:12:21.978100Z","iopub.execute_input":"2021-12-28T12:12:21.978759Z","iopub.status.idle":"2021-12-28T12:12:22.821569Z","shell.execute_reply.started":"2021-12-28T12:12:21.978714Z","shell.execute_reply":"2021-12-28T12:12:22.820552Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Converting to PyTorch dataset format\n\nWe load the images & masks using **cv2**, and then divide by 225 after converting them to NumPy array, so that all images/masks are in the range of [0,1].\nThen we apply transformations to it using the Albumentations library. \n\nFor the images, we first convert them from `HxWxC` to `CxHxW` format, then to `torch.tensor` of type `float32`, & then finally Normalize the color channels.\n\nFor the masks, since they only have `HxW`, we add another dimension so it becomes `HxWxC`, then we convert it to `CxHxW`. Then we convert it to `torch.tensor` of type `float32`. We don't need to normalize the masks.","metadata":{}},{"cell_type":"code","source":"class BrainDataset(data.Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        image = cv2.imread(self.df.iloc[idx, 0])\n        image = np.array(image)/255.\n        mask = cv2.imread(self.df.iloc[idx, 1], 0)\n        mask = np.array(mask)/255.\n        \n        if self.transform is not None:\n            aug = self.transform(image=image, mask=mask)\n            image = aug['image']\n            mask = aug['mask']\n        \n        image = image.transpose((2,0,1))\n        image = torch.from_numpy(image).type(torch.float32)\n        image = tt.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))(image)\n        mask = np.expand_dims(mask, axis=-1).transpose((2,0,1))\n        mask = torch.from_numpy(mask).type(torch.float32)\n        \n        return image, mask","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:12:22.822581Z","iopub.execute_input":"2021-12-28T12:12:22.822813Z","iopub.status.idle":"2021-12-28T12:12:22.836918Z","shell.execute_reply.started":"2021-12-28T12:12:22.822779Z","shell.execute_reply":"2021-12-28T12:12:22.835803Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### Augmentations","metadata":{}},{"cell_type":"code","source":"train_transform = A.Compose([\n    A.Resize(width=128, height=128, p=1.0),\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.5),\n    A.RandomRotate90(p=0.5),\n    A.ShiftScaleRotate(shift_limit=0.01, scale_limit=0.04, rotate_limit=0, p=0.25),\n])\n\nval_transform = A.Compose([\n    A.Resize(width=128, height=128, p=1.0),\n    A.HorizontalFlip(p=0.5),\n])\n\ntest_transform = A.Compose([\n    A.Resize(width=128, height=128, p=1.0)\n])","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:12:22.838787Z","iopub.execute_input":"2021-12-28T12:12:22.839415Z","iopub.status.idle":"2021-12-28T12:12:22.851298Z","shell.execute_reply.started":"2021-12-28T12:12:22.839370Z","shell.execute_reply":"2021-12-28T12:12:22.850551Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"set_seed()\n\ntrain_ds = BrainDataset(train_df, train_transform)\nval_ds = BrainDataset(val_df, val_transform)\ntest_ds = BrainDataset(test_df, test_transform)","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:12:22.854356Z","iopub.execute_input":"2021-12-28T12:12:22.854707Z","iopub.status.idle":"2021-12-28T12:12:22.862156Z","shell.execute_reply.started":"2021-12-28T12:12:22.854669Z","shell.execute_reply":"2021-12-28T12:12:22.861391Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def dataset_info(dataset): \n    print(f'Size of dataset: {len(dataset)}')\n    index = random.randint(1, 40)\n    img, label = dataset[index]\n    print(f'Sample-{index} Image size: {img.shape}, Mask: {label.shape}\\n')","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:12:22.863573Z","iopub.execute_input":"2021-12-28T12:12:22.863932Z","iopub.status.idle":"2021-12-28T12:12:22.870217Z","shell.execute_reply.started":"2021-12-28T12:12:22.863891Z","shell.execute_reply":"2021-12-28T12:12:22.869398Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"print('Train dataset:')\ndataset_info(train_ds)\nprint('Validation dataset:')\ndataset_info(val_ds)\nprint('Test dataset:')\ndataset_info(test_ds)","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:12:22.871688Z","iopub.execute_input":"2021-12-28T12:12:22.872110Z","iopub.status.idle":"2021-12-28T12:12:22.978992Z","shell.execute_reply.started":"2021-12-28T12:12:22.872073Z","shell.execute_reply":"2021-12-28T12:12:22.978125Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Creating Dataloaders\n\nWe create dataloaders to load data in batches. ","metadata":{}},{"cell_type":"code","source":"batch_size = 64\n\nset_seed()\ntrain_dl = DataLoader(train_ds, \n                      batch_size, \n                      shuffle=True, \n                      num_workers=2,  \n                      pin_memory=True)  \n\nset_seed()\nval_dl = DataLoader(val_ds, \n                    batch_size,   \n                    num_workers=2, \n                    pin_memory=True)\n\ntest_dl = DataLoader(val_ds, \n                    batch_size,   \n                    num_workers=2, \n                    pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:12:22.981382Z","iopub.execute_input":"2021-12-28T12:12:22.981886Z","iopub.status.idle":"2021-12-28T12:12:22.991086Z","shell.execute_reply.started":"2021-12-28T12:12:22.981841Z","shell.execute_reply":"2021-12-28T12:12:22.990224Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"images, masks = next(iter(train_dl))\nprint(images.shape)\nprint(masks.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:12:22.995824Z","iopub.execute_input":"2021-12-28T12:12:22.996121Z","iopub.status.idle":"2021-12-28T12:12:28.175876Z","shell.execute_reply.started":"2021-12-28T12:12:22.996082Z","shell.execute_reply":"2021-12-28T12:12:28.174972Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"The size of one batch is `64xCx128x128` where C is the number of channels in image/mask.","metadata":{}},{"cell_type":"markdown","source":"### Viewing samples from a batch\n\nTo view the samples in a batch we first need to denormalize the images by passing in same *mean* & *std*.","metadata":{}},{"cell_type":"code","source":"def denormalize(images):\n    means = torch.tensor([0.485, 0.456, 0.406]).reshape(1, 3, 1, 1)\n    stds = torch.tensor([0.229, 0.224, 0.225]).reshape(1, 3, 1, 1)\n    return images * stds + means\n\ndef show_batch(dl):\n    for images, masks in dl:\n        fig1, ax1 = plt.subplots(figsize=(24, 24))\n        ax1.set_xticks([]); ax1.set_yticks([])\n        denorm_images = denormalize(images)\n        ax1.imshow(make_grid(denorm_images[:13], nrow=13).permute(1, 2, 0).clamp(0,1))\n        \n        fig2, ax2 = plt.subplots(figsize=(24, 24))\n        ax2.set_xticks([]); ax2.set_yticks([])\n        ax2.imshow(make_grid(masks[:13], nrow=13).permute(1, 2, 0).clamp(0,1))\n        break\n        \nshow_batch(train_dl)","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:12:28.178491Z","iopub.execute_input":"2021-12-28T12:12:28.179286Z","iopub.status.idle":"2021-12-28T12:12:30.825312Z","shell.execute_reply.started":"2021-12-28T12:12:28.179238Z","shell.execute_reply":"2021-12-28T12:12:30.824262Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Defining the UNET model","metadata":{}},{"cell_type":"code","source":"class DoubleConv(nn.Module):\n    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n    def __init__(self, in_channels, out_channels, mid_channels=None):\n        super().__init__()\n        if not mid_channels:\n            mid_channels = out_channels\n        self.double_conv = nn.Sequential(\n            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(mid_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True))\n    def forward(self, x):\n        return self.double_conv(x)\n    \nclass Down(nn.Module):\n    \"\"\"Downscaling with maxpool then double conv\"\"\"\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.maxpool_conv = nn.Sequential(\n            nn.MaxPool2d(2),\n            DoubleConv(in_channels, out_channels))\n    def forward(self, x):\n        return self.maxpool_conv(x)\n    \nclass Up(nn.Module):\n    \"\"\"Upscaling then double conv\"\"\"\n    def __init__(self, in_channels, out_channels, bilinear=True):\n        super().__init__()\n        if bilinear:\n            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n            self.conv = DoubleConv(in_channels, out_channels, in_channels//2)\n        else:\n            self.up = nn.ConvTranspose2d(in_channels, in_channels//2, kernel_size=2, stride=2)\n            self.conv = DoubleConv(in_channels, out_channels)\n    def forward(self, x1, x2):\n        x1 = self.up(x1)\n        diffY = x2.size()[2] - x1.size()[2]\n        diffX = x2.size()[3] - x1.size()[3]\n        \n        x1 = F.pad(x1, [diffX//2, diffX-diffX//2,\n                        diffY//2, diffY-diffY//2])\n        x = torch.cat([x2, x1], dim=1)\n        return self.conv(x)\n\nclass OutConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(OutConv, self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=1),\n            nn.Sigmoid())\n    def forward(self, x):\n        return self.conv(x)","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:12:30.827333Z","iopub.execute_input":"2021-12-28T12:12:30.827720Z","iopub.status.idle":"2021-12-28T12:12:30.845102Z","shell.execute_reply.started":"2021-12-28T12:12:30.827671Z","shell.execute_reply":"2021-12-28T12:12:30.844322Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"class UNet(nn.Module):\n    def __init__(self, n_channels, n_classes, bilinear=True):\n        super(UNet, self).__init__()\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.bilinear = bilinear\n        \n        self.inc = DoubleConv(n_channels, 64)\n        self.down1 = Down(64, 128)\n        self.down2 = Down(128, 256)\n        self.down3 = Down(256, 512)\n        factor = 2 if bilinear else 1\n        self.down4 = Down(512, 1024//factor)\n        self.up1 = Up(1024, 512//factor, bilinear)\n        self.up2 = Up(512, 256//factor, bilinear)        \n        self.up3 = Up(256, 128//factor, bilinear)        \n        self.up4 = Up(128, 64, bilinear)        \n        self.outc = OutConv(64, n_classes)\n    \n    def forward(self, x):\n        x1 = self.inc(x)\n        x2 = self.down1(x1)\n        x3 = self.down2(x2)\n        x4 = self.down3(x3)\n        x5 = self.down4(x4)\n        x = self.up1(x5, x4)\n        x = self.up2(x, x3)\n        x = self.up3(x, x2)\n        x = self.up4(x, x1)\n        logits = self.outc(x)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:12:30.848109Z","iopub.execute_input":"2021-12-28T12:12:30.848737Z","iopub.status.idle":"2021-12-28T12:12:30.861069Z","shell.execute_reply.started":"2021-12-28T12:12:30.848705Z","shell.execute_reply":"2021-12-28T12:12:30.860254Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"model = UNet(3, 1).to(device)\nout = model(torch.randn(1, 3, 128, 128).to(device))\nprint(out.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:12:30.862520Z","iopub.execute_input":"2021-12-28T12:12:30.862872Z","iopub.status.idle":"2021-12-28T12:12:35.990678Z","shell.execute_reply.started":"2021-12-28T12:12:30.862831Z","shell.execute_reply":"2021-12-28T12:12:35.989688Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## Metric & Loss fn\n\n\nTo measure accuracy, the metric we choose is the **DICE coefficient**. *Dice Coefficient* is `2 * the Area of Overlap divided by the total number of pixels in both images`.\n\n**DICE Loss** is equal to `1 - DICE Coefficient`.\n\nHowever, a better loss function is the `sum of BCELoss & DICE Loss`.","metadata":{}},{"cell_type":"code","source":"def dice_coef_metric(pred, label):\n    intersection = 2.0 * (pred * label).sum()\n    union = pred.sum() + label.sum()\n    if pred.sum() == 0 and label.sum() == 0:\n        return 1.\n    return intersection / union\n\ndef dice_coef_loss(pred, label):\n    smooth = 1.0\n    intersection = 2.0 * (pred * label).sum() + smooth\n    union = pred.sum() + label.sum() + smooth\n    return 1 - (intersection / union)\n\ndef bce_dice_loss(pred, label):\n    dice_loss = dice_coef_loss(pred, label)\n    bce_loss = nn.BCELoss()(pred, label)\n    return dice_loss + bce_loss","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:12:35.992156Z","iopub.execute_input":"2021-12-28T12:12:35.992602Z","iopub.status.idle":"2021-12-28T12:12:36.001054Z","shell.execute_reply.started":"2021-12-28T12:12:35.992559Z","shell.execute_reply":"2021-12-28T12:12:36.000115Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"## Training ","metadata":{}},{"cell_type":"markdown","source":"### Train Loop","metadata":{}},{"cell_type":"code","source":"def train_loop(model, loader, loss_func):\n    model.train()\n    train_losses = []\n    train_dices = []\n    \n#     for i, (image, mask) in enumerate(tqdm(loader)):\n    for i, (image, mask) in enumerate(loader):\n        image = image.to(device)\n        mask = mask.to(device)\n        outputs = model(image)\n        out_cut = np.copy(outputs.data.cpu().numpy())\n        out_cut[np.nonzero(out_cut < 0.5)] = 0.0\n        out_cut[np.nonzero(out_cut >= 0.5)] = 1.0            \n\n        dice = dice_coef_metric(out_cut, mask.data.cpu().numpy())\n        loss = loss_func(outputs, mask)\n        train_losses.append(loss.item())\n        train_dices.append(dice)\n\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        \n    return train_dices, train_losses","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:12:36.002747Z","iopub.execute_input":"2021-12-28T12:12:36.003284Z","iopub.status.idle":"2021-12-28T12:12:36.015913Z","shell.execute_reply.started":"2021-12-28T12:12:36.003242Z","shell.execute_reply":"2021-12-28T12:12:36.015033Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"### Validation loop","metadata":{}},{"cell_type":"code","source":"def eval_loop(model, loader, loss_func, training=True):\n    model.eval()\n    val_loss = 0\n    val_dice = 0\n    with torch.no_grad():\n        for step, (image, mask) in enumerate(loader):\n            image = image.to(device)\n            mask = mask.to(device)\n    \n            outputs = model(image)\n            loss = loss_func(outputs, mask)\n            \n            out_cut = np.copy(outputs.data.cpu().numpy())\n            out_cut[np.nonzero(out_cut < 0.5)] = 0.0\n            out_cut[np.nonzero(out_cut >= 0.5)] = 1.0\n            dice = dice_coef_metric(out_cut, mask.data.cpu().numpy())\n            \n            val_loss += loss\n            val_dice += dice\n        \n        val_mean_dice = val_dice / step\n        val_mean_loss = val_loss / step\n        \n        if training:\n            scheduler.step(val_mean_dice)\n        \n    return val_mean_dice, val_mean_loss","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:12:36.017628Z","iopub.execute_input":"2021-12-28T12:12:36.018254Z","iopub.status.idle":"2021-12-28T12:12:36.029836Z","shell.execute_reply.started":"2021-12-28T12:12:36.018213Z","shell.execute_reply":"2021-12-28T12:12:36.029003Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"### Train Function","metadata":{}},{"cell_type":"code","source":"def train_model(train_loader, val_loader, loss_func, optimizer, scheduler, num_epochs):\n    train_loss_history = []\n    train_dice_history = []\n    val_loss_history = []\n    val_dice_history = []\n    \n    for epoch in range(num_epochs):\n        train_dices, train_losses = train_loop(model, train_loader, loss_func)\n        train_mean_dice = np.array(train_dices).mean()\n        train_mean_loss = np.array(train_losses).mean()\n        val_mean_dice, val_mean_loss = eval_loop(model, val_loader, loss_func)\n        \n        train_loss_history.append(np.array(train_losses).mean())\n        train_dice_history.append(np.array(train_dices).mean())\n        val_loss_history.append(val_mean_loss)\n        val_dice_history.append(val_mean_dice)\n        \n        print('Epoch: {}/{} |  Train Loss: {:.3f}, Val Loss: {:.3f}, Train DICE: {:.3f}, Val DICE: {:.3f}'.format(epoch+1, num_epochs,\n                                                                                                                 train_mean_loss,\n                                                                                                                 val_mean_loss,\n                                                                                                                 train_mean_dice,\n                                                                                                                 val_mean_dice))\n        \n\n    return train_loss_history, train_dice_history, val_loss_history, val_dice_history","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:12:36.031265Z","iopub.execute_input":"2021-12-28T12:12:36.032026Z","iopub.status.idle":"2021-12-28T12:12:36.042085Z","shell.execute_reply.started":"2021-12-28T12:12:36.031983Z","shell.execute_reply":"2021-12-28T12:12:36.041327Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"### Hyperparameters\n\nThe learning rate scheduler that we use here is **ReduceLROnPlateau** in `max` mode with `patience=3` which\nreduce the LR if quantity monitored stops increasing after 3 epochs.","metadata":{}},{"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=3)\nnum_epochs = 30","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:12:36.043587Z","iopub.execute_input":"2021-12-28T12:12:36.044021Z","iopub.status.idle":"2021-12-28T12:12:36.056725Z","shell.execute_reply.started":"2021-12-28T12:12:36.043982Z","shell.execute_reply":"2021-12-28T12:12:36.055864Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"%%time\ntrain_loss_history, train_dice_history, val_loss_history, val_dice_history = train_model(train_dl, val_dl, bce_dice_loss, optimizer, scheduler, num_epochs)","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:12:36.060382Z","iopub.execute_input":"2021-12-28T12:12:36.061405Z","iopub.status.idle":"2021-12-28T12:31:10.526962Z","shell.execute_reply.started":"2021-12-28T12:12:36.061364Z","shell.execute_reply":"2021-12-28T12:31:10.525078Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"## DICE Score History","metadata":{}},{"cell_type":"code","source":"def plot_dice_history(model_name, train_dice_history, val_dice_history, num_epochs):\n    \n    x = np.arange(num_epochs)\n    fig = plt.figure(figsize=(10, 6))\n    plt.plot(x, train_dice_history, label='Train DICE', lw=3, c=\"b\")\n    plt.plot(x, val_dice_history, label='Validation DICE', lw=3, c=\"r\")\n\n    plt.title(f\"{model_name}\", fontsize=20)\n    plt.legend(fontsize=12)\n    plt.xlabel(\"Epoch\", fontsize=15)\n    plt.ylabel(\"DICE\", fontsize=15)\n\n    plt.show()\n    \nplot_dice_history('UNET', train_dice_history, val_dice_history, num_epochs)","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:31:10.529067Z","iopub.execute_input":"2021-12-28T12:31:10.529422Z","iopub.status.idle":"2021-12-28T12:31:10.768866Z","shell.execute_reply.started":"2021-12-28T12:31:10.529371Z","shell.execute_reply":"2021-12-28T12:31:10.768076Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"## Loss History","metadata":{}},{"cell_type":"code","source":"def plot_loss_history(model_name, train_loss_history, val_loss_history, num_epochs):\n    \n    x = np.arange(num_epochs)\n    fig = plt.figure(figsize=(10, 6))\n    plt.plot(x, train_loss_history, label='Train Loss', lw=3, c=\"b\")\n    plt.plot(x, val_loss_history, label='Validation Loss', lw=3, c=\"r\")\n\n    plt.title(f\"{model_name}\", fontsize=20)\n    plt.legend(fontsize=12)\n    plt.xlabel(\"Epoch\", fontsize=15)\n    plt.ylabel(\"Loss\", fontsize=15)\n\n    plt.show()\n    \nplot_loss_history('UNET', train_loss_history, val_loss_history, num_epochs)","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:31:10.770183Z","iopub.execute_input":"2021-12-28T12:31:10.770529Z","iopub.status.idle":"2021-12-28T12:31:10.998687Z","shell.execute_reply.started":"2021-12-28T12:31:10.770487Z","shell.execute_reply":"2021-12-28T12:31:10.997983Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"## Prediction on Test set","metadata":{}},{"cell_type":"code","source":"%%time\ntest_dice, test_loss = eval_loop(model, test_dl, bce_dice_loss, training=False)\nprint(\"Mean IoU/DICE: {:.3f}%, Loss: {:.3f}\".format((100*test_dice), test_loss))","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:31:11.000064Z","iopub.execute_input":"2021-12-28T12:31:11.000537Z","iopub.status.idle":"2021-12-28T12:31:13.897472Z","shell.execute_reply.started":"2021-12-28T12:31:11.000500Z","shell.execute_reply":"2021-12-28T12:31:13.896576Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"test_sample = test_df[test_df[\"diagnosis\"] == 1].sample(24).values[0]\nimage = cv2.resize(cv2.imread(test_sample[0]), (128, 128))\nmask = cv2.resize(cv2.imread(test_sample[1]), (128, 128))\n\n# pred\npred = torch.tensor(image.astype(np.float32) / 255.).unsqueeze(0).permute(0,3,1,2)\npred = tt.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))(pred)\npred = model(pred.to(device))\npred = pred.detach().cpu().numpy()[0,0,:,:]\n\npred_t = np.copy(pred)\npred_t[np.nonzero(pred_t < 0.3)] = 0.0\npred_t[np.nonzero(pred_t >= 0.3)] = 255.\npred_t = pred_t.astype(\"uint8\")\n\n# plot\nfig, ax = plt.subplots(nrows=2,  ncols=2, figsize=(10, 10))\n\nax[0, 0].imshow(image)\nax[0, 0].set_title(\"image\")\nax[0, 1].imshow(mask)\nax[0, 1].set_title(\"mask\")\nax[1, 0].imshow(pred)\nax[1, 0].set_title(\"prediction\")\nax[1, 1].imshow(pred_t)\nax[1, 1].set_title(\"prediction with threshold\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:31:13.898881Z","iopub.execute_input":"2021-12-28T12:31:13.899609Z","iopub.status.idle":"2021-12-28T12:31:14.696593Z","shell.execute_reply.started":"2021-12-28T12:31:13.899576Z","shell.execute_reply":"2021-12-28T12:31:14.695807Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"## Saving the Model","metadata":{}},{"cell_type":"code","source":"torch.save(model.state_dict(), 'brain-mri-unet.pth')","metadata":{"execution":{"iopub.status.busy":"2021-12-28T12:31:14.697689Z","iopub.execute_input":"2021-12-28T12:31:14.698042Z","iopub.status.idle":"2021-12-28T12:31:14.823150Z","shell.execute_reply.started":"2021-12-28T12:31:14.698006Z","shell.execute_reply":"2021-12-28T12:31:14.822318Z"},"trusted":true},"execution_count":29,"outputs":[]}]}